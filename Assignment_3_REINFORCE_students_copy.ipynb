{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "For this part of the assignment, we are going to use the corridor environment, which has been defined in this notebook. The corridor is shown in the graph below. The reward is -1 per step as usual. The grey block is the terminal state. In each of the three nonterminal states there are only two actions, ***right*** and ***left***. These actions have their usual consequences in the first and third states (left causes no movement in the first state), but in the second state they are reversed, so that right moves to the left and left moves to the right.\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "We are going to implment the REINFORCE algorithm and evaluate it on this environment."
      ],
      "metadata": {
        "id": "DXV_DmegYlC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2018 Sergii Bondariev (sergeybondarev@gmail.com)                    #\n",
        "# 2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)                  #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def true_value(p):\n",
        "    \"\"\" True value of the first state\n",
        "    Args:\n",
        "        p (float): probability of the action 'right'.\n",
        "    Returns:\n",
        "        True value of the first state.\n",
        "        The expression is obtained by manually solving the easy linear system\n",
        "        of Bellman equations using known dynamics.\n",
        "    \"\"\"\n",
        "    return (2 * p - 4) / (p * (1 - p))\n",
        "\n",
        "\n",
        "class ShortCorridor:\n",
        "    \"\"\"\n",
        "    Short corridor environment\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = 0\n",
        "\n",
        "    def step(self, go_right):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            go_right (bool): chosen action\n",
        "        Returns:\n",
        "            tuple of (reward, episode terminated?)\n",
        "        \"\"\"\n",
        "        if self.state == 0 or self.state == 2:\n",
        "            if go_right:\n",
        "                self.state += 1\n",
        "            else:\n",
        "                self.state = max(0, self.state - 1)\n",
        "        else:\n",
        "            if go_right:\n",
        "                self.state -= 1\n",
        "            else:\n",
        "                self.state += 1\n",
        "\n",
        "        if self.state == 3:\n",
        "            # terminal state\n",
        "            return 0, True\n",
        "        else:\n",
        "            return -1, False\n",
        "\n",
        "def softmax(x):\n",
        "    t = np.exp(x - np.max(x))\n",
        "    return t / np.sum(t)\n",
        "\n"
      ],
      "metadata": {
        "id": "HcaweCH7vlwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: REINFORCE algorithm**\n",
        "\n",
        "In this part, you need to implement the REINFORCE algorithm. You will need to do the following:        \n",
        "(1) Initialize a differentiable policy parameterized by $\\theta$.                 \n",
        "(2) Generate an episode with policy. Keep rolling out to get new state s1, reward r and done d from environment until the terminate state.\n",
        "\n",
        "(3) Calculate returns $G$ for each step of the episode $t = 0, 1, \\ldots, T-1$.                         \n",
        "(4) Update policy.                                                          \n",
        "\n",
        "Enter your code in the block."
      ],
      "metadata": {
        "id": "FavfDYrRwxK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReinforceAgent:\n",
        "    \"\"\"\n",
        "    ReinforceAgent that follows algorithm\n",
        "    'REINFORNCE Monte-Carlo Policy-Gradient Control (episodic)'\n",
        "    \"\"\"\n",
        "\n",
        "        ##############################################################################\n",
        "        #                              ENTER YOUR CODE                               #\n",
        "        ##############################################################################\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hXcmsdkKvvhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: REINFORCE with baseline (episodic)**\n",
        "\n",
        "In this section, you need to implement another version of REINFORCE with baseline. Addition to the implementation in vanilla REINFORCE, you need to add a differentiable state-value function w, which is initialized as self.w = 0. You need to use this w as the baseline to reduce the variance of REINFORCE by replacing $G$ with advantage $\\delta = G - w$. Then you can update w and $\\theta$ as\n",
        "\n",
        "$\\begin{aligned}\n",
        "& \\mathbf{w} \\leftarrow \\mathbf{w}+\\alpha^{\\mathbf{w}} \\delta \\nabla \\hat{v}\\left(S_t, \\mathbf{w}\\right) \\\\\n",
        "& \\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta}+\\alpha^{\\boldsymbol{\\theta}} \\gamma^t \\delta \\nabla \\ln \\pi\\left(A_t \\mid S_t, \\boldsymbol{\\theta}\\right)\n",
        "\\end{aligned}$.\n",
        "\n",
        "For more details about the algorithm, refer to the lecture notes LN17 or Chapter 13 \"REINFORCE with Baseline (episodic)\" in the book \"Reinforcement learning: an introduction\" by Richard Sutton.\n",
        "\n",
        "Enter your code in the block."
      ],
      "metadata": {
        "id": "7dds8UjsxbZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReinforceBaselineAgent(ReinforceAgent):\n",
        "\n",
        "\n",
        "\n",
        "        ##############################################################################\n",
        "        #                             ENTER YOUR CODE                               #\n",
        "        ##############################################################################\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YlfbRDsAxbk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3.1: Evaluation with different learning rate in REINFORCE**\n",
        "\n",
        "In this part, we will show the performance of REINFORCE on the short-corridor gridworld with different hyperparameter $\\alpha$ settings as {2e-3, 2e-4, 2e-5}. The number of trials is 100, and the number of episode is 1000. Discount rate is  $\\gamma=1$.\n",
        "\n",
        "You need to plot the results which show the total reward on episode with these three different learning rates, which is averaged over 100 runs."
      ],
      "metadata": {
        "id": "QgUeKZGh-OYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Q3_1():\n",
        "    num_trials = 100\n",
        "    num_episodes = 1000\n",
        "    gamma = 1\n",
        "\n",
        "\n",
        "\n",
        "    ##############################################################################\n",
        "    #                             ENTER YOUR CODE                               #\n",
        "    ##############################################################################\n"
      ],
      "metadata": {
        "id": "1U_Aqopl8smj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3_1()"
      ],
      "metadata": {
        "id": "EEkueO1UGEIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3.2: Evaluation of REINFORCE w/o baseline**\n",
        "\n",
        "In this part, we will show the performance of REINFORCE and REINFORCE-with-baseline on the short-corridor gridworld. The hyperparameter $\\alpha$ for REINFORCE is set as {2e-4}. The hyperparameter $\\alpha, \\alpha^w$ for REINFORCE with baseline is set as {2e-3, 2e-2}. The number of trials is 100, and the number of episode is 1000. Discount rate is  $\\gamma=1$.\n",
        "\n",
        "You need to plot the results which show the total reward on episode with these three different learning rates, which is averaged over 100 runs."
      ],
      "metadata": {
        "id": "KGV728g4_5sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Q3_2():\n",
        "    num_trials = 100\n",
        "    num_episodes = 1000\n",
        "    alpha = 2e-4\n",
        "    gamma = 1\n",
        "\n",
        "    ##############################################################################\n",
        "    #                             ENTER YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "HWroWKif9iqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3_2()"
      ],
      "metadata": {
        "id": "XKRfuqewF_Je"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}